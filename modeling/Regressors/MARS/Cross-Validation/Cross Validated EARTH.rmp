<?xml version="1.0" encoding="UTF-8"?><process version="9.4.000-SNAPSHOT">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000-SNAPSHOT" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="python_operator_framework:create_python_learner" compatibility="0.0.005-SNAPSHOT" expanded="true" height="82" name="Create Learner Object" width="90" x="45" y="136">
        <parameter key="description" value="Train SGD Classifier"/>
        <parameter key="train script" value="import numpy as np&#10;import pandas as pd&#10;from pyearth import Earth&#10;&#10;def separate_features_targets(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features fit the model on.&#10;&#9;targets&#10;&#9;&#9;pd.DataFrame with targets.&#10;&#9;&quot;&quot;&quot;&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;targets = data[name]&#10;&#10;&#9;features = data.drop(targets.name, axis=1)&#10;&#10;&#9;return features, targets&#10;&#10;&#10;def rm_main(params,data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Fits the MARS model and returns in-sample predictions.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame created from the RapidMiner ExampleSet by the Execute Python operator.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;model&#10;&#9;&#9;Fitted MARS model.&#10;&#9;output&#10;&#9;&#9;pd.DataFrame with in-sample forecasts.&#10;&#9;data&#10;&#9;&#9;pd.DataFrame passed as argument.&#10;&#9;&quot;&quot;&quot;&#10;&#9;params_dict = process_params(params)&#10;&#9;features, targets = separate_features_targets(data)&#10;&#10;&#9;model = Earth(max_terms=params_dict['max_terms'], max_degree=params_dict['max_degree'],&#10;&#9;&#9;&#9;&#9;allow_missing=params_dict['allow_missing'], penalty=params_dict['penalty'], endspan_alpha=params_dict['endspan_alpha'],&#10;&#9;&#9;&#9;&#9;endspan=params_dict['endspan'], minspan_alpha=params_dict['minspan_alpha'], minspan=params_dict['minspan'], thresh=params_dict['thresh'],&#10;&#9;&#9;&#9;&#9;zero_tol=params_dict['zero_tol'], min_search_points=params_dict['min_search_points'], check_every=params_dict['check_every'],&#10;&#9;&#9;&#9;&#9;allow_linear=params_dict['allow_linear'], use_fast=params_dict['use_fast'], fast_K=params_dict['fast_K'], fast_h=params_dict['fast_h'],&#10;&#9;&#9;&#9;&#9;smooth=params_dict['smooth'], enable_pruning=params_dict['enable_pruning'],&#10;&#9;&#9;&#9;&#9;feature_importance_type=params_dict['feature_importance_type'], verbose=params_dict['verbose'])&#10;&#9;&#9;&#9;&#9;&#10;&#9;&#10;&#9;model.fit(np.array(features), np.array(targets))&#10;&#10;#&#9;prediction = pd.DataFrame(model.predict(features))&#10;&#9;#output = data.join(prediction)&#10;&#10;&#9;return model, &quot;html output&quot;&#10;&#9;&#10;&#9;&#10;&#10;def process_params(params):&#10;&#9;for i in params.index:&#10;&#9;&#9;print(params['type'][i])&#10;&#9;&#9;if (params['type'][i] == 'ParameterTypeInt'):&#10;&#9;&#9;&#9;params['value'][i] = int(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeString'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeDouble'):&#10;&#9;&#9;&#9;params['value'][i] = float(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeBoolean'):&#10;&#9;&#9;&#9;params['value'][i] = bool(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeStringCategory'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeCategory'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#10;&#9;&#10;&#9;params_dict = dict(zip(params.key,params.value))&#10;&#9;#replace string None with KeyWord None&#10;&#9;#for key,value in params_dict.items():&#10;&#9;#&#9;if value == 'None':&#10;&#9;#&#9;&#9;params_dict[key] = None&#10;&#9;return params_dict&#10;&#10;&#10;def processString(strvalue):&#10;&#9;if(strvalue == 'None'):&#10;&#9;&#9;strvalue = None&#10;&#9;return strvalue"/>
        <parameter key="apply script" value="from statsmodels.tsa.arima_model import ARIMA&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;package_dict = {'LabelPropagation': 'scikit-learn', 'PassiveAggressiveClassifier': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SGDClassifier': 'scikit-learn', 'SGDRegressor': 'scikit-learn', 'Earth': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SMOTE': 'scikit-learn', 'ARIMAResultsWrapper': 'statsmodels'}&#10;&#10;def rm_main(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn or statsmodels model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;package_name = get_package_name(stored_model)&#10;&#9;if package_name == 'scikit-learn':&#10;&#9;&#9;data, stored_model = apply_sklearn(stored_model, data)&#10;&#9;elif package_name == 'statsmodels':&#10;&#9;&#9;data, stored_model = apply_statsmodels(stored_model, data)&#10;&#10;&#9;return data&#10;&#10;def get_package_name(stored_model):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Returns the package name of the stored_model in order to call the right method for performing classification or&#10;&#9;regression. The methods are different for models in scikit-learn and statsmodels packages.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return package_dict[type(stored_model).__name__]&#10;&#10;&#10;def preprocessing_sklearn(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels/targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels/targets to pass to the model during training.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#9;&#10;&#9;return features, labels&#10;&#10;&#10;def apply_sklearn(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;features, labels = preprocessing_sklearn(data)&#10;&#10;&#9;predicted_labels = pd.DataFrame(stored_model.predict(features))&#10;&#9;predictionColumnName = 'Prediction(' +  labels.name + ')'&#10;&#9;data[predictionColumnName] = predicted_labels&#10;&#10;&#9;data.rm_metadata[predictionColumnName] = (None,&quot;prediction&quot;)&#10;&#9;data.rm_metadata[labels.name] = (data.rm_metadata[labels.name][0],&quot;label&quot;)&#10;&#9;return data, stored_model&#10;&#10;&#10;def __getnewargs__(self):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Overrides a method that causes a bug when trying to serialise the ARIMA model.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))&#10;&#10;&#10;def preprocessing_statsmodels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Preprocesses the data to prepare for performing prediction with the ARIMA model.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with the dataset.&#10;&#9;Returns&#10;&#9;----------&#10;&#9;date_time_column&#10;&#9;&#9;pd.Series with date_time data.&#10;&#9;prediction_column&#10;&#9;&#9;pd.Series with target data.&#10;&#9;&quot;&quot;&quot;&#10;&#9;date_time_column = pd.Series()&#10;&#9;prediction_column = pd.Series()&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_type == 'date_time':&#10;&#9;&#9;&#9;date_time_column = data[name]&#10;&#9;&#9;if attribute_role == 'prediction':&#10;&#9;&#9;&#9;prediction_column = data[name]&#10;&#10;&#9;return date_time_column, prediction_column&#10;&#10;&#10;def apply_statsmodels(model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9; Performs out-of-sample forecast on data.&#10;&#10;&#9; Parameters&#10;&#9; ----------&#10;&#9; model : statsmodels.tsa.arima_model.ARIMA&#10;&#9;&#9;Pre-trained ARIMA model.&#10;&#9; data : pd.DataFrame&#10;&#9;&#9;DataFrame with data on which to forecast.&#10;&#10;&#9; Returns&#10;&#9; -------&#10;&#9; result_df&#10;&#9;&#9; DataFrame with out-of-sample forecasts.&#10;&#9; model&#10;&#9;&#9; Fitted ARIMA model.&#10;&#9; &quot;&quot;&quot;&#10;&#9;ARIMA.__getnewargs__ = __getnewargs__&#10;&#10;&#9;date_time_column, prediction_column = preprocessing_statsmodels(data)&#10;&#9;start = date_time_column.iloc[0]&#10;&#9;end = date_time_column.iloc[-1]&#10;&#10;&#9;predictions = model.predict(start=start, end=end, typ='levels')&#10;&#9;result_df = pd.DataFrame(data=predictions.values, columns=[prediction_column.name])&#10;&#9;result_df[date_time_column.name] = date_time_column&#10;&#9;result_df.rm_metadata = {date_time_column.name: ('date_time', 'id'), prediction_column.name: ('real', 'prediction')}&#10;&#10;&#9;return result_df, model&#10;&#10;&#10;"/>
        <parameter key="params XML definition" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;model name=&quot;MARS&quot;&gt;&#10;&#9;&lt;parameter name=&quot;max_terms&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The maximum number of terms generated by the forward pass. All memory is allocated at the beginning of the forward pass, so setting max_terms to a very high number on a system with insufficient memory may cause a MemoryError at the start of the forward pass.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;400&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;max_degree&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The maximum degree of terms generated by the forward pass.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;allow_missing&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;If True, use missing data method.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;False&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;penalty&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;A smoothing parameter used to calculate GCV and GRSQ. Used during the pruning pass and to determine whether to add a hinge or linear basis function during the forward pass.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;3.0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;endspan_alpha&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;descriptipon&gt;A parameter controlling the calculation of the endspan parameter.&lt;/descriptipon&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.05&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;endspan&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The number of extreme data values of each feature not eligible as knot locations. If endspan is set to -1 (default) then the endspan parameter is calculated based on endspan_alpha (above). If endspan is set to a positive integer then endspan_alpha is ignored.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;-1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;-1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;minspan_alpha&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Parameter controlling the calculation of the minspan parameter.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.05&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;minspan&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The minimal number of data points between knots. If minspan is set to -1 (default) then the minspan parameter is calculated based on minspan_alpha (above). If minspan is set to a positive integer then minspan_alpha is ignored.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;-1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;-1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;thresh&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Parameter used when evaluating stopping conditions for the forward pass. If either RSQ &gt; 1 - thresh or if RSQ increases by less than thresh for a forward pass iteration then the forward pass is terminated.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.001&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;zero_tol&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Used when determining whether a floating point number is zero during the forward pass. This is important in determining linear dependence and in the fast update procedure. There should normally be no reason to change zero_tol from its default. However, if nans are showing up during the forward pass or the forward pass seems to be terminating unexpectedly, consider adjusting zero_tol.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1e-12&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;min_search_points&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Used to calculate check_every.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;100&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;check_every&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;If check_every &gt; 0, only one of every check_every sorted data points is considered as a candidate knot. If check_every is set to -1 then the check_every parameter is calculated based on min_search_points.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;-1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;-1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;allow_linear&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;If True, the forward pass will check the GCV of each new pair of terms and, if it’s not an improvement on a single term with no knot (called a linear term, although it may actually be a product of a linear term with some other parent term), then only that single, knotless term will be used. If False, that behavior is disabled and all terms will have knots except those with variables specified by the linvars argument.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;use_fast&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;If True, use an approximation procedure to speed up the forward pass.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;defualt&gt;False&lt;/defualt&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;fast_K&quot; parent=&quot;use_fast&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Defines the maximum number of basis functions to look at when we search for a parent, that is we look at only the fast_K top terms ranked by the mean squared error of the model the last time the term was chosen as a parent. The smaller fast_K is, the more gains in speed we get but the more approximate is the result.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;activation_value&gt;True&lt;/activation_value&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;5&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;fast_h&quot; parent=&quot;use_fast&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Determines the number of iterations before repassing through all the variables when searching for the variable to use for a given parent term. Before reaching fast_h number of iterations only the last chosen variable for the parent term is used. The bigger fast_h is, the more speed gains we get, but the result is less exact.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;activation_value&gt;True&lt;/activation_value&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;smooth&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;If True, the model will be smoothed such that it has continuous first derivatives.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;False&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;enable_pruning&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;If False, the pruning pass will be skipped.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;feature_importance_type&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Specify which kind of feature importance criteria to compute.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;value&gt;gcv&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;rss&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;nb_subsets&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;None&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;None&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;verbose&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Verbosity level.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&lt;/model&gt;"/>
      </operator>
      <operator activated="true" breakpoints="after" class="store" compatibility="9.4.000-SNAPSHOT" expanded="true" height="68" name="Store" width="90" x="246" y="34">
        <parameter key="repository_entry" value="EARTH"/>
      </operator>
      <operator activated="true" class="retrieve" compatibility="9.4.000-SNAPSHOT" expanded="true" height="68" name="Retrieve Polynomial" width="90" x="112" y="238">
        <parameter key="repository_entry" value="//Samples/data/Polynomial"/>
      </operator>
      <operator activated="true" class="concurrency:cross_validation" compatibility="9.3.000" expanded="true" height="145" name="Cross Validation" width="90" x="246" y="238">
        <parameter key="split_on_batch_attribute" value="false"/>
        <parameter key="leave_one_out" value="false"/>
        <parameter key="number_of_folds" value="10"/>
        <parameter key="sampling_type" value="automatic"/>
        <parameter key="use_local_random_seed" value="false"/>
        <parameter key="local_random_seed" value="1992"/>
        <parameter key="enable_parallel_execution" value="false"/>
        <process expanded="true">
          <operator activated="true" class="retrieve" compatibility="9.4.000-SNAPSHOT" expanded="true" height="68" name="Retrieve EARTH" width="90" x="45" y="340">
            <parameter key="repository_entry" value="EARTH"/>
          </operator>
          <operator activated="true" class="python_operator_framework:process_python_learner" compatibility="0.0.005-SNAPSHOT" expanded="true" height="82" name="Build Python Model" width="90" x="179" y="85">
            <parameter key="max_terms" value="400"/>
            <parameter key="max_degree" value="1"/>
            <parameter key="allow_missing" value="false"/>
            <parameter key="penalty" value="3.0"/>
            <parameter key="endspan_alpha" value="0.05"/>
            <parameter key="endspan" value="-1"/>
            <parameter key="minspan_alpha" value="0.05"/>
            <parameter key="minspan" value="-1"/>
            <parameter key="thresh" value="0.001"/>
            <parameter key="zero_tol" value="1.0E-12"/>
            <parameter key="min_search_points" value="100"/>
            <parameter key="check_every" value="-1"/>
            <parameter key="allow_linear" value="true"/>
            <parameter key="use_fast" value="false"/>
            <parameter key="fast_K" value="5"/>
            <parameter key="fast_h" value="1"/>
            <parameter key="smooth" value="false"/>
            <parameter key="enable_pruning" value="true"/>
            <parameter key="feature_importance_type" value="None"/>
            <parameter key="verbose" value="0"/>
          </operator>
          <connect from_port="training set" to_op="Build Python Model" to_port="training set"/>
          <connect from_op="Retrieve EARTH" from_port="output" to_op="Build Python Model" to_port="pythonlearner"/>
          <connect from_op="Build Python Model" from_port="model" to_port="model"/>
          <portSpacing port="source_training set" spacing="0"/>
          <portSpacing port="sink_model" spacing="0"/>
          <portSpacing port="sink_through 1" spacing="0"/>
        </process>
        <process expanded="true">
          <operator activated="true" class="apply_model" compatibility="9.4.000-SNAPSHOT" expanded="true" height="82" name="Apply Model (2)" width="90" x="112" y="34">
            <list key="application_parameters"/>
            <parameter key="create_view" value="false"/>
          </operator>
          <operator activated="true" class="performance_regression" compatibility="9.4.000-SNAPSHOT" expanded="true" height="82" name="Performance" width="90" x="380" y="34">
            <parameter key="main_criterion" value="first"/>
            <parameter key="root_mean_squared_error" value="true"/>
            <parameter key="absolute_error" value="true"/>
            <parameter key="relative_error" value="true"/>
            <parameter key="relative_error_lenient" value="true"/>
            <parameter key="relative_error_strict" value="true"/>
            <parameter key="normalized_absolute_error" value="true"/>
            <parameter key="root_relative_squared_error" value="true"/>
            <parameter key="squared_error" value="true"/>
            <parameter key="correlation" value="false"/>
            <parameter key="squared_correlation" value="false"/>
            <parameter key="prediction_average" value="false"/>
            <parameter key="spearman_rho" value="false"/>
            <parameter key="kendall_tau" value="false"/>
            <parameter key="skip_undefined_labels" value="true"/>
            <parameter key="use_example_weights" value="true"/>
          </operator>
          <connect from_port="model" to_op="Apply Model (2)" to_port="model"/>
          <connect from_port="test set" to_op="Apply Model (2)" to_port="unlabelled data"/>
          <connect from_op="Apply Model (2)" from_port="labelled data" to_op="Performance" to_port="labelled data"/>
          <connect from_op="Performance" from_port="performance" to_port="performance 1"/>
          <portSpacing port="source_model" spacing="0"/>
          <portSpacing port="source_test set" spacing="0"/>
          <portSpacing port="source_through 1" spacing="0"/>
          <portSpacing port="sink_test set results" spacing="0"/>
          <portSpacing port="sink_performance 1" spacing="0"/>
          <portSpacing port="sink_performance 2" spacing="0"/>
        </process>
      </operator>
      <connect from_op="Create Learner Object" from_port="pythonLearner" to_op="Store" to_port="input"/>
      <connect from_op="Retrieve Polynomial" from_port="output" to_op="Cross Validation" to_port="example set"/>
      <connect from_op="Cross Validation" from_port="model" to_port="result 1"/>
      <connect from_op="Cross Validation" from_port="performance 1" to_port="result 2"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
      <description align="center" color="yellow" colored="false" height="105" resized="false" width="180" x="421" y="48">Step 1&lt;br/&gt;Create a learner Object that can be re used anytime you want to to use Label propogation Algorithm&lt;br/&gt;</description>
    </process>
  </operator>
</process>
