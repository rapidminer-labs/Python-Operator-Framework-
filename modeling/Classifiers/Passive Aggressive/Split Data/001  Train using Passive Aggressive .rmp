<?xml version="1.0" encoding="UTF-8"?><process version="9.4.000-SNAPSHOT">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000-SNAPSHOT" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="python_operator_framework:create_python_learner" compatibility="0.0.005-SNAPSHOT" expanded="true" height="82" name="Create Learner Object" width="90" x="179" y="289">
        <parameter key="description" value="This python script is used to fit using the the passive aggressive model."/>
        <parameter key="train script" value="from sklearn import linear_model&#10;&#10;import numpy as np&#10;import pandas&#10;&#10;&#10;def separate_features_labels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#10;&#9;return features, labels&#10;&#10;&#10;def rm_main(params,data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Fits the passive aggressive classifier.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame created from the RapidMiner ExampleSet by the Execute Python operator.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;model&#10;&#9;&#9;Fitted passive aggressive classifier.&#10;&#9;data&#10;&#9;&#9;pd.DataFrame passed as argument.&#10;&#9;&quot;&quot;&quot;&#10;&#9;params_dict = process_params(params)&#10;&#9;features, labels = separate_features_labels(data)&#10;&#10;&#9;clf = linear_model.PassiveAggressiveClassifier(C=params_dict['C'], fit_intercept=params_dict['fit_intercept'], max_iter=params_dict['max_iter'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;   shuffle=params_dict['shuffle'], verbose=params_dict['verbose'], loss=params_dict['loss'], n_jobs=&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;   params_dict['n_jobs'], random_state=params_dict['random_state'], warm_start=params_dict['warm_start'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;   class_weight=params_dict['class_weight'])&#10;&#9;model = clf.fit(np.array(features), np.array(labels))&#10;&#10;&#9;return model, &quot;html string&quot;&#10;&#9;&#10;&#9;&#10;def process_params(params):&#10;&#9;for i in params.index:&#10;&#9;&#9;print(params['type'][i])&#10;&#9;&#9;if (params['type'][i] == 'ParameterTypeInt'):&#10;&#9;&#9;&#9;params['value'][i] = int(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeString'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeDouble'):&#10;&#9;&#9;&#9;params['value'][i] = float(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeBoolean'):&#10;&#9;&#9;&#9;params['value'][i] = bool(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeStringCategory'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeCategory'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#10;&#9;&#10;&#9;params_dict = dict(zip(params.key,params.value))&#10;&#9;#replace string None with KeyWord None&#10;&#9;#for key,value in params_dict.items():&#10;&#9;#&#9;if value == 'None':&#10;&#9;#&#9;&#9;params_dict[key] = None&#10;&#9;return params_dict&#10;&#10;&#10;def processString(strvalue):&#10;&#9;if(strvalue == 'None'):&#10;&#9;&#9;strvalue = None&#10;&#9;return strvalue"/>
        <parameter key="apply script" value="from statsmodels.tsa.arima_model import ARIMA&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;package_dict = {'LabelPropagation': 'scikit-learn', 'PassiveAggressiveClassifier': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SGDClassifier': 'scikit-learn', 'SGDRegressor': 'scikit-learn', 'Earth': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SMOTE': 'scikit-learn', 'ARIMAResultsWrapper': 'statsmodels'}&#10;&#10;def rm_main(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn or statsmodels model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;package_name = get_package_name(stored_model)&#10;&#9;if package_name == 'scikit-learn':&#10;&#9;&#9;data, stored_model = apply_sklearn(stored_model, data)&#10;&#9;elif package_name == 'statsmodels':&#10;&#9;&#9;data, stored_model = apply_statsmodels(stored_model, data)&#10;&#10;&#9;return data&#10;&#10;def get_package_name(stored_model):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Returns the package name of the stored_model in order to call the right method for performing classification or&#10;&#9;regression. The methods are different for models in scikit-learn and statsmodels packages.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return package_dict[type(stored_model).__name__]&#10;&#10;&#10;def preprocessing_sklearn(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels/targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels/targets to pass to the model during training.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#9;&#10;&#9;return features, labels&#10;&#10;&#10;def apply_sklearn(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;features, labels = preprocessing_sklearn(data)&#10;&#10;&#9;predicted_labels = pd.DataFrame(stored_model.predict(features))&#10;&#9;predictionColumnName = 'Prediction(' +  labels.name + ')'&#10;&#9;data[predictionColumnName] = predicted_labels&#10;&#9;#use datatype from python, hence setting to None&#10;&#9;data.rm_metadata[predictionColumnName] = (None,&quot;prediction&quot;)&#10;&#9;data.rm_metadata[labels.name] = (data.rm_metadata[labels.name][0],&quot;label&quot;)&#10;&#9;return data, stored_model&#10;&#10;&#10;def __getnewargs__(self):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Overrides a method that causes a bug when trying to serialise the ARIMA model.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))&#10;&#10;&#10;def preprocessing_statsmodels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Preprocesses the data to prepare for performing prediction with the ARIMA model.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with the dataset.&#10;&#9;Returns&#10;&#9;----------&#10;&#9;date_time_column&#10;&#9;&#9;pd.Series with date_time data.&#10;&#9;prediction_column&#10;&#9;&#9;pd.Series with target data.&#10;&#9;&quot;&quot;&quot;&#10;&#9;date_time_column = pd.Series()&#10;&#9;prediction_column = pd.Series()&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_type == 'date_time':&#10;&#9;&#9;&#9;date_time_column = data[name]&#10;&#9;&#9;if attribute_role == 'prediction':&#10;&#9;&#9;&#9;prediction_column = data[name]&#10;&#10;&#9;return date_time_column, prediction_column&#10;&#10;&#10;def apply_statsmodels(model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9; Performs out-of-sample forecast on data.&#10;&#10;&#9; Parameters&#10;&#9; ----------&#10;&#9; model : statsmodels.tsa.arima_model.ARIMA&#10;&#9;&#9;Pre-trained ARIMA model.&#10;&#9; data : pd.DataFrame&#10;&#9;&#9;DataFrame with data on which to forecast.&#10;&#10;&#9; Returns&#10;&#9; -------&#10;&#9; result_df&#10;&#9;&#9; DataFrame with out-of-sample forecasts.&#10;&#9; model&#10;&#9;&#9; Fitted ARIMA model.&#10;&#9; &quot;&quot;&quot;&#10;&#9;ARIMA.__getnewargs__ = __getnewargs__&#10;&#10;&#9;date_time_column, prediction_column = preprocessing_statsmodels(data)&#10;&#9;start = date_time_column.iloc[0]&#10;&#9;end = date_time_column.iloc[-1]&#10;&#10;&#9;predictions = model.predict(start=start, end=end, typ='levels')&#10;&#9;result_df = pd.DataFrame(data=predictions.values, columns=[prediction_column.name])&#10;&#9;result_df[date_time_column.name] = date_time_column&#10;&#9;result_df.rm_metadata = {date_time_column.name: ('date_time', 'id'), prediction_column.name: ('real', 'prediction')}&#10;&#10;&#9;return result_df, model&#10;&#10;&#10;"/>
        <parameter key="params XML definition" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;model name=&quot;PassiveAggressive&quot;&gt;&#10;&#9;&lt;parameter name=&quot;C&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;Maximum step size in regularisation.&lt;/description&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1.0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;fit_intercept&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;Whether the intercept should be estimated or not. If False, the data is assumed to be already centred.&lt;/description&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;max_iter&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;The maximum number of passes over the training data (aka epochs).&lt;/description&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;5&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;tol&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;The stopping criterion.&lt;/description&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1e-3&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;shuffle&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;Whether the training data should be shuffled after each epoch.&lt;/description&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;verbose&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;Verbosity level.&lt;/description&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;Loss function to be used.&lt;/description&gt;&#10;&#9;&#9;&lt;value&gt;hinge&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_hinge&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;hinge&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;n_jobs&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Number of CPUs to use to do the OVA computation.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;-1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;64&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;-1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;random_state&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;description&gt;Seed of the pseudo-random number generator to use when shuffling data.&lt;/description&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;warm_start&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;When set to True, reuse the solution of the previous call to fit as initialisation, otherwise, just erase the previous solution.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;False&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;class_weight&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Weights associated with classes. If not given, all classes are supposed to have weight one.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;value&gt;None&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;balanced&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;None&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&lt;/model&gt;"/>
      </operator>
      <operator activated="true" class="retrieve" compatibility="9.4.000-SNAPSHOT" expanded="true" height="68" name="Retrieve Weighting" width="90" x="179" y="136">
        <parameter key="repository_entry" value="//Samples/data/Weighting"/>
      </operator>
      <operator activated="true" class="split_data" compatibility="9.4.000-SNAPSHOT" expanded="true" height="103" name="Split Data" width="90" x="313" y="136">
        <enumeration key="partitions">
          <parameter key="ratio" value="0.8"/>
          <parameter key="ratio" value="0.2"/>
        </enumeration>
        <parameter key="sampling_type" value="automatic"/>
        <parameter key="use_local_random_seed" value="false"/>
        <parameter key="local_random_seed" value="1992"/>
      </operator>
      <operator activated="true" class="python_operator_framework:process_python_learner" compatibility="0.0.005-SNAPSHOT" expanded="true" height="82" name="Build Python Model" width="90" x="380" y="289">
        <parameter key="C" value="1.0"/>
        <parameter key="fit_intercept" value="true"/>
        <parameter key="max_iter" value="1024"/>
        <parameter key="tol" value="0.001"/>
        <parameter key="shuffle" value="true"/>
        <parameter key="verbose" value="0"/>
        <parameter key="loss" value="hinge"/>
        <parameter key="n_jobs" value="-1"/>
        <parameter key="random_state" value="0"/>
        <parameter key="warm_start" value="false"/>
        <parameter key="class_weight" value="None"/>
      </operator>
      <operator activated="true" class="apply_model" compatibility="9.4.000-SNAPSHOT" expanded="true" height="82" name="Apply Model" width="90" x="648" y="187">
        <list key="application_parameters"/>
        <parameter key="create_view" value="false"/>
      </operator>
      <connect from_op="Create Learner Object" from_port="pythonLearner" to_op="Build Python Model" to_port="pythonlearner"/>
      <connect from_op="Retrieve Weighting" from_port="output" to_op="Split Data" to_port="example set"/>
      <connect from_op="Split Data" from_port="partition 1" to_op="Build Python Model" to_port="training set"/>
      <connect from_op="Split Data" from_port="partition 2" to_op="Apply Model" to_port="unlabelled data"/>
      <connect from_op="Build Python Model" from_port="model" to_op="Apply Model" to_port="model"/>
      <connect from_op="Apply Model" from_port="labelled data" to_port="result 2"/>
      <connect from_op="Apply Model" from_port="model" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
    </process>
  </operator>
</process>
