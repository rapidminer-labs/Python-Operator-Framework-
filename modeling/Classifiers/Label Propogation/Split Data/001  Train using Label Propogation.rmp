<?xml version="1.0" encoding="UTF-8"?><process version="9.4.000-SNAPSHOT">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000-SNAPSHOT" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="python_operator_framework:create_python_learner" compatibility="0.0.005-SNAPSHOT" expanded="true" height="82" name="Create Learner Object" width="90" x="179" y="289">
        <parameter key="description" value="This python script is used to fit using the the label propagation model."/>
        <parameter key="train script" value="from sklearn import semi_supervised&#10;&#10;import numpy as np&#10;import pandas as pd&#10;def rm_main(params,data):&#10;    &quot;&quot;&quot;&#10;    Fits the label propagation model.&#10;&#10;    Parameters&#10;    ----------&#10;    data : pd.DataFrame&#10;        DataFrame created from the RapidMiner ExampleSet by the Execute Python operator.&#10;&#10;    Returns&#10;    -------&#10;    model&#10;        Fitted label propagation model.&#10;    data&#10;        pd.DataFrame with labels assigned to each sample via transduction.&#10;    &quot;&quot;&quot;&#10;    params_dict = process_params(params)&#10;    &#10;    features, labels = separate_features_labels(data)&#10;&#10;    clf = semi_supervised.LabelPropagation(kernel=params_dict['kernel'], gamma=params_dict['gamma'], n_neighbors=params_dict['n_neighbours'],&#10;                                           max_iter=params_dict['max_iter'], tol=params_dict['tol'], n_jobs=params_dict['n_jobs'])&#10;    model = clf.fit(np.array(features), np.array(labels))&#10;&#10;    data[labels.name] = model.transduction_&#10;&#10;    return model, &quot;outputhtml&quot;&#10;&#10;&#10;&#10;def separate_features_labels(data):&#10;    &quot;&quot;&quot;&#10;    Using the RapidMiner attribute metadata, separates features and labels in the DataFrame passed as argument. Fills the missing labels with -1.&#10;&#10;    Parameters&#10;    ----------&#10;    data : pd.DataFrame&#10;        Dataset.&#10;&#10;    Returns&#10;    -------&#10;    features&#10;        pd.DataFrame with features to train the label propagation model on.&#10;    labels&#10;        pd.DataFrame with labels to pass to the label propagation model during training.&#10;    &quot;&quot;&quot;&#10;    for name in data.columns.values:&#10;        attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;        if attribute_role == 'label':&#10;            labels = pd.Series.fillna(data[name], value=-1)&#10;&#10;    features = data.drop(labels.name, axis=1)&#10;    return features, labels&#10;&#10;&#10;&#10;def process_params(params):&#10;&#9;for i in params.index:&#10;&#9;&#9;print(params['type'][i])&#10;&#9;&#9;if (params['type'][i] == 'ParameterTypeInt'):&#10;&#9;&#9;&#9;params['value'][i] = int(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeString'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeDouble'):&#10;&#9;&#9;&#9;params['value'][i] = float(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeBoolean'):&#10;&#9;&#9;&#9;params['value'][i] = bool(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeStringCategory'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#9;&#9;elif (params['type'][i] == 'ParameterTypeCategory'):&#10;&#9;&#9;&#9;params['value'][i] = processString(params['value'][i])&#10;&#10;&#9;&#10;&#9;params_dict = dict(zip(params.key,params.value))&#10;&#9;#replace string None with KeyWord None&#10;&#9;#for key,value in params_dict.items():&#10;&#9;#&#9;if value == 'None':&#10;&#9;#&#9;&#9;params_dict[key] = None&#10;&#9;return params_dict&#10;&#10;&#10;def processString(strvalue):&#10;&#9;if(strvalue == 'None'):&#10;&#9;&#9;strvalue = None&#10;&#9;return strvalue&#10;"/>
        <parameter key="apply script" value="from statsmodels.tsa.arima_model import ARIMA&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;package_dict = {'LabelPropagation': 'scikit-learn', 'PassiveAggressiveClassifier': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SGDClassifier': 'scikit-learn', 'SGDRegressor': 'scikit-learn', 'Earth': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SMOTE': 'scikit-learn', 'ARIMAResultsWrapper': 'statsmodels'}&#10;&#10;def rm_main(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn or statsmodels model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;package_name = get_package_name(stored_model)&#10;&#9;if package_name == 'scikit-learn':&#10;&#9;&#9;data, stored_model = apply_sklearn(stored_model, data)&#10;&#9;elif package_name == 'statsmodels':&#10;&#9;&#9;data, stored_model = apply_statsmodels(stored_model, data)&#10;&#10;&#9;return data&#10;&#10;def get_package_name(stored_model):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Returns the package name of the stored_model in order to call the right method for performing classification or&#10;&#9;regression. The methods are different for models in scikit-learn and statsmodels packages.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return package_dict[type(stored_model).__name__]&#10;&#10;&#10;def preprocessing_sklearn(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels/targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels/targets to pass to the model during training.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#9;&#10;&#9;return features, labels&#10;&#10;&#10;def apply_sklearn(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;features, labels = preprocessing_sklearn(data)&#10;&#10;&#9;predicted_labels = pd.DataFrame(stored_model.predict(features))&#10;&#9;predictionColumnName = 'Prediction(' +  labels.name + ')'&#10;&#9;data[predictionColumnName] = predicted_labels&#10;&#9;data.rm_metadata[predictionColumnName] = (data.rm_metadata[labels.name][0],&quot;prediction&quot;)&#10;&#9;data.rm_metadata[labels.name] = (data.rm_metadata[labels.name][0],&quot;label&quot;)&#10;&#9;return data, stored_model&#10;&#10;&#10;def __getnewargs__(self):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Overrides a method that causes a bug when trying to serialise the ARIMA model.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))&#10;&#10;&#10;def preprocessing_statsmodels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Preprocesses the data to prepare for performing prediction with the ARIMA model.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with the dataset.&#10;&#9;Returns&#10;&#9;----------&#10;&#9;date_time_column&#10;&#9;&#9;pd.Series with date_time data.&#10;&#9;prediction_column&#10;&#9;&#9;pd.Series with target data.&#10;&#9;&quot;&quot;&quot;&#10;&#9;date_time_column = pd.Series()&#10;&#9;prediction_column = pd.Series()&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_type == 'date_time':&#10;&#9;&#9;&#9;date_time_column = data[name]&#10;&#9;&#9;if attribute_role == 'prediction':&#10;&#9;&#9;&#9;prediction_column = data[name]&#10;&#10;&#9;return date_time_column, prediction_column&#10;&#10;&#10;def apply_statsmodels(model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9; Performs out-of-sample forecast on data.&#10;&#10;&#9; Parameters&#10;&#9; ----------&#10;&#9; model : statsmodels.tsa.arima_model.ARIMA&#10;&#9;&#9;Pre-trained ARIMA model.&#10;&#9; data : pd.DataFrame&#10;&#9;&#9;DataFrame with data on which to forecast.&#10;&#10;&#9; Returns&#10;&#9; -------&#10;&#9; result_df&#10;&#9;&#9; DataFrame with out-of-sample forecasts.&#10;&#9; model&#10;&#9;&#9; Fitted ARIMA model.&#10;&#9; &quot;&quot;&quot;&#10;&#9;ARIMA.__getnewargs__ = __getnewargs__&#10;&#10;&#9;date_time_column, prediction_column = preprocessing_statsmodels(data)&#10;&#9;start = date_time_column.iloc[0]&#10;&#9;end = date_time_column.iloc[-1]&#10;&#10;&#9;predictions = model.predict(start=start, end=end, typ='levels')&#10;&#9;result_df = pd.DataFrame(data=predictions.values, columns=[prediction_column.name])&#10;&#9;result_df[date_time_column.name] = date_time_column&#10;&#9;result_df.rm_metadata = {date_time_column.name: ('date_time', 'id'), prediction_column.name: ('real', 'prediction')}&#10;&#10;&#9;return result_df, model&#10;&#10;&#10;"/>
        <parameter key="params XML definition" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;model name=&quot;LabelPropagation&quot;&gt;&#10;&#9;&lt;parameter name=&quot;kernel&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;String identifier for kernel function to use.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;        &lt;value&gt;knn&lt;/value&gt;&#10;        &lt;value&gt;rbf&lt;/value&gt;&#10;        &lt;default&gt;rbf&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;gamma&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Parameter for rbf kernel.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;20&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;n_neighbours&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Parameter for k-NN kernel.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;7&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;max_iter&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Number of epochs.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1024&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;tol&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Threshold to consider the system at steady state.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;1e-3&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;n_jobs&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Number of cores to use.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;-1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;64&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;-1&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&lt;/model&gt;"/>
      </operator>
      <operator activated="true" class="retrieve" compatibility="9.4.000-SNAPSHOT" expanded="true" height="68" name="Retrieve Weighting" width="90" x="179" y="136">
        <parameter key="repository_entry" value="//Samples/data/Weighting"/>
      </operator>
      <operator activated="true" class="split_data" compatibility="9.4.000-SNAPSHOT" expanded="true" height="103" name="Split Data" width="90" x="313" y="136">
        <enumeration key="partitions">
          <parameter key="ratio" value="0.8"/>
          <parameter key="ratio" value="0.2"/>
        </enumeration>
        <parameter key="sampling_type" value="automatic"/>
        <parameter key="use_local_random_seed" value="false"/>
        <parameter key="local_random_seed" value="1992"/>
      </operator>
      <operator activated="true" class="python_operator_framework:process_python_learner" compatibility="0.0.005-SNAPSHOT" expanded="true" height="82" name="Build Python Model" width="90" x="380" y="289">
        <parameter key="kernel" value="rbf"/>
        <parameter key="gamma" value="20.0"/>
        <parameter key="n_neighbours" value="7"/>
        <parameter key="max_iter" value="1024"/>
        <parameter key="tol" value="0.001"/>
        <parameter key="n_jobs" value="-1"/>
      </operator>
      <operator activated="true" class="apply_model" compatibility="9.4.000-SNAPSHOT" expanded="true" height="82" name="Apply Model" width="90" x="648" y="187">
        <list key="application_parameters"/>
        <parameter key="create_view" value="false"/>
      </operator>
      <connect from_op="Create Learner Object" from_port="pythonLearner" to_op="Build Python Model" to_port="pythonlearner"/>
      <connect from_op="Retrieve Weighting" from_port="output" to_op="Split Data" to_port="example set"/>
      <connect from_op="Split Data" from_port="partition 1" to_op="Build Python Model" to_port="training set"/>
      <connect from_op="Split Data" from_port="partition 2" to_op="Apply Model" to_port="unlabelled data"/>
      <connect from_op="Build Python Model" from_port="model" to_op="Apply Model" to_port="model"/>
      <connect from_op="Apply Model" from_port="labelled data" to_port="result 2"/>
      <connect from_op="Apply Model" from_port="model" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
    </process>
  </operator>
</process>
